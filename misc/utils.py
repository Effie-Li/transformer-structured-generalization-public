import os
import glob
import torch
import numpy as np
import scipy as sp
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
from scipy.stats import spearmanr
from einops import rearrange, repeat

from data.dataset import MultiTaskDataset, MultiTaskDataModule
from model.transformer import MultitaskModelModule

def fetch_runs(api, project):
    '''
    uses wandb api to fetch information about all runs in a project
    args
    ----
        api : wandb api instance
        project : string
            the project repo

    returns
    -------
    runs_df : pandas dataframe
        containing runid, group, name, model config columns, and run summary columns
    '''

    runs = api.runs(project)

    summary_list, config_list, name_list, group_list, id_list = [], [], [], [], []
    for run in runs: 
        # .summary contains the output keys/values for metrics like accuracy.
        #  We call ._json_dict to omit large files 
        summary_list.append(run.summary._json_dict)

        # .config contains the hyperparameters.
        #  We remove special values that start with _.
        config_list.append(
            {k: v for k,v in run.config.items()
            if not k.startswith('_')})

        # .name is the human-readable name of the run.
        name_list.append(run.name)
        group_list.append(run.group)
        id_list.append(run.id)

    summary = pd.json_normalize(summary_list)
    config = pd.json_normalize(config_list)

    runs_df = pd.DataFrame({
        'id': id_list,
        'group': group_list,
        'name': name_list
    })

    runs_df = pd.concat([runs_df, config, summary], axis=1)
    return runs_df, config_list, id_list

def get_learning_curve_data(api, project, runid, keys):
    run = api.run(project + '/' + runid)
    run_history = run.scan_history(keys=keys)
    result = {k: [row[k] for row in run_history] for k in keys}
    result = pd.DataFrame.from_dict(result)
    return result

def get_ckptfs_from_run(ckpt_dir, runid):

    '''
    args
    ----
    ckpt_dir : string
        path to root directory containing all runs
    runid : string
        random run identifier generated by wandb

    returns
    -------
    ckpts : list of string
        filenames of all checkpoint files
    '''

    path = ckpt_dir + '/' + runid + '/checkpoints/'
    files = glob.glob(path+'*.ckpt')
    files = [f for f in files if 'last' not in f ]
    strs = [file.split('/')[-1][:-5] for file in files] # extract the 'epoch=X-step=XXX' part in the fname
    epochs = [int(s.split('-')[0].split('=')[1]) for s in strs]
    steps = [int(s.split('-')[1].split('=')[1]) for s in strs]
    ckpts = pd.DataFrame({
        'epoch': epochs,
        'step': steps,
        'fname': files
    })
    ckpts.sort_values(['epoch','step'], inplace=True)
    ckpts.reset_index(drop=True, inplace=True)
    return ckpts

def load_model(model_class, ckpt_f):
    '''
    generic model loader given a checkpoint file
    '''
    model = model_class.load_from_checkpoint(ckpt_f)
    return model

def calc_pairwise_euclidean_dist(x):
    # x : torch.tensor
    # shape (batch, n_items, rep_dim)
    bsz, n, d = x.shape
    transformed = repeat(x, 'b n d -> b n n2 d', n2=n)
    transposed = rearrange(transformed, 'b n1 n2 d -> b n2 n1 d')
    squared_diffs = (transformed - transposed).pow(2)
    squared_dists = squared_diffs.sum(-1)
    return squared_dists

def mat_corr(pred_mat, gt_mat):
    '''
    computes the Spearman corr between predicted and ground-truth metrics
    for each item in each seq

    args
    ----
    pred_mat/gt_mat : torch.tensor
        shape (batch, n_item, dim)
    
    returns
    -------
    torch.tensor
        shape (batch, n_item)
    '''
    bsz = pred_mat.shape[0]
    pred_mat = rearrange(pred_mat, 'b n d -> (b n) d')
    gt_mat = rearrange(gt_mat, 'b n d -> (b n) d')
    spearmanrs = [spearmanr(pred, gt).correlation for pred, gt in zip(pred_mat, gt_mat)]
    spearmanrs = rearrange(torch.tensor(spearmanrs), '(b n) -> b n', b=bsz)
    return spearmanrs

def reconstruct_model_and_dm(local_run_root, runid, config, train_idx, val_idx, batch_size=1000):
    '''
    load the last.ckpt file in the checkpoint directory for `runid` and reconstruct its training datamodule
    '''
    ckpt_fs = glob.glob(local_run_root+'%s/checkpoints/*.ckpt'%runid)
    latest_ckpt = max(ckpt_fs, key=os.path.getctime)
    model = load_model(MultitaskModelModule, latest_ckpt)
    if 'feature_order' not in config['data'].keys():
        config['data']['feature_order'] = ['shape','color']
    dataset = MultiTaskDataset(config)
    dm = MultiTaskDataModule(dataset, batch_size=batch_size,
                             train_idx=train_idx, val_idx=val_idx) # recreate the train/val split
    return model, dm

def batch_to_device(batch, device, except_keys):
    return {k:batch[k].to(device) for k in batch.keys() if k not in except_keys}

def func_over_all_ckpts(local_run_root, runid, func, device='cpu'):
    '''
    run function over model loaded from all checkpoints
    '''
    ckpts = get_ckptfs_from_run(ckpt_dir=local_run_root, runid=runid)
    result = list(map(lambda f: func(load_model(MultitaskModelModule, f).to(device)), ckpts.fname.values))
    return result, ckpts

def func_over_all_runs(local_run_root, runids, func, device='cpu'):
    '''
    run function over model loaded from all last.ckpt for all given runids
    '''
    ckpts = [local_run_root + '/' + runid + '/checkpoints/last.ckpt' for runid in runids]
    result = list(map(lambda f: func(load_model(MultitaskModelModule, f).to(device)), ckpts))
    return result, ckpts

def plot_line_and_ribbon(ax, x, y, color, alpha=0.25, **plt_kwargs):
    ax.plot(x, np.nanmean(y, 0), color=color, **plt_kwargs)
    ax.fill_between(x, np.nanmean(y, 0)-sp.stats.sem(y), np.nanmean(y, 0)+sp.stats.sem(y), color=color, alpha=alpha)

def discrete_color_gradient(c1, c2, n):
    c1=np.array(mpl.colors.to_rgb(c1))
    c2=np.array(mpl.colors.to_rgb(c2))
    colors = []
    for x in range(n):
        colors.append(mpl.colors.to_hex((1-x/n)*c1 + x/n*c2))
    return colors

def extract_and_reorder_attn_maps(model, batch, batch_idx):

    '''
    plots the attention weights for one sequence in batch, 
    query (y-axis) starts from the <eos> after input seq (first query) and ends at the last item in output seq (last query)
    source includes both input and output sequences
    '''

    depth = model.hparams.depth
    n_head = model.hparams.n_heads
    n_task = model.hparams.n_task
    n_feature = model.hparams.n_feature
    include_task_token = model.hparams.use_task_token

    if type(n_head)==int: n_head = [n_head]*depth

    # extract one sequence at batch_idx as a batch
    seq_lens = model._calc_batch_seq_len(batch['src']['item'], teacher_forcing=True)
    seq_len = seq_lens[batch_idx]
    mini_batch = {'src': {'item': batch['src']['item'][batch_idx:batch_idx+1, :seq_len*2], # (1, seq_len*2, item_dim)
                          'label': batch['src']['label'][batch_idx:batch_idx+1, :seq_len*2]}}

    # generate first-level labels and sort index (used to label items and reorder attention maps for viz)
    if not include_task_token:
        seq = rearrange(mini_batch['src']['item'][0,:seq_len,n_task+1:], 'l (f d) -> l f d', f=n_feature).argmax(-1)
        sorted_seq = rearrange(mini_batch['src']['item'][0,seq_len:seq_len*2,n_task+1:], 'l (f d) -> l f d', f=n_feature).argmax(-1)
    else:
        seq = rearrange(mini_batch['src']['item'][0,1:seq_len,n_task+1:], 'l (f d) -> l f d', f=n_feature).argmax(-1)
        sorted_seq = rearrange(mini_batch['src']['item'][0,seq_len+1:seq_len*2,n_task+1:], 'l (f d) -> l f d', f=n_feature).argmax(-1)
    sort_idx = [seq.cpu().numpy().tolist().index(sorted_item) for sorted_item in sorted_seq.cpu().numpy().tolist()] # include <eos>

    attention_maps = model.get_attention_maps(mini_batch, batch_processed=True, teacher_forcing=True) # list of (1, n_head, seq_len*2, seq_len*2)
    attention_maps = [x[0]for x in attention_maps] # list of (n_head, seq_len*2, seq_len*2)

    reordered_maps = {}
    for l in range(depth):
        for h in range(n_head[l]):
            maps = attention_maps[l][h, seq_len-1:2*seq_len-1].cpu() # (seq_len, n_item*2)
            # reorder the portion representing the randomized input sequence
            if not include_task_token:
                maps[:,:seq_len] = maps[:,:seq_len][:,sort_idx] # sorted portion attending to unsorted portion
            else:
                maps[:,1:seq_len] = maps[:,1:seq_len][:,sort_idx]
            reordered_maps['L%d-H%d'%(l,h)] = maps

    return reordered_maps, sorted_seq # sorted_seq does not include task token